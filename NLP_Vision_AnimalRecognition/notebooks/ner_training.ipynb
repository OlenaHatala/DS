{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Training Notebook\n",
    "This notebook contains data preprocessing, model training, saving and loading weights, and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 16:42:02.795170: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/olena/opt/anaconda3/envs/task2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "project_root = os.path.abspath(\"..\")  \n",
    "sys.path.append(os.path.join(project_root, \"models\"))\n",
    "\n",
    "from ner_model import NerModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset is generated using script <code>datasets/text/generate_dataset.py</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tokens': ['The', 'squirrel', 'is', 'looking', 'for', 'its', 'family.'], 'labels': ['O', 'B-SQUIRREL', 'O', 'O', 'O', 'O', 'O']}, {'tokens': ['There', 'was', 'a', 'chicken', 'near', 'the', 'river.'], 'labels': ['O', 'O', 'O', 'B-CHICKEN', 'O', 'O', 'O']}, {'tokens': ['I', 'saw', 'a', 'horse', 'at', 'the', 'animal', 'shelter.'], 'labels': ['O', 'O', 'O', 'B-HORSE', 'O', 'O', 'O', 'O']}, {'tokens': ['I', 'saw', 'a', 'cat', 'at', 'the', 'animal', 'shelter.'], 'labels': ['O', 'O', 'O', 'B-CAT', 'O', 'O', 'O', 'O']}, {'tokens': ['Did', 'you', 'hear', 'that?', 'It', 'was', 'a', 'wolf.'], 'labels': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../datasets/text/ner_dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2100, Validation: 603, Test: 297\n"
     ]
    }
   ],
   "source": [
    "train_data, temp_data = train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "valid_data, test_data = train_test_split(temp_data, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Validation: {len(valid_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['Look', 'at', 'how', 'fast', 'the', 'butterfly', 'can', 'run!'],\n",
       " 'labels': ['O', 'O', 'O', 'O', 'O', 'B-BUTTERFLY', 'O', 'O']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [sample[\"tokens\"] for sample in train_data]\n",
    "y_train = [sample[\"labels\"] for sample in train_data]\n",
    "\n",
    "x_val = [sample[\"tokens\"] for sample in valid_data]\n",
    "y_val = [sample[\"tokens\"] for sample in valid_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ner_model = NerModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING and SAVING WEIGHTS\n",
    "If you want to train model by yourself then run this block of cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.train(x_train, y_train, x_val, y_val, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.save_weights(\"../src/weights/new_ner_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING WEIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weights were saved from a model trained with parameters <code>epochs=10, batch_size=32</code>. \n",
    "And the result of training was <br><i>loss: 0.9633 - accuracy: 0.9383<br>val_loss: 1.0828 - val_accuracy: 0.9028</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.load_weights(\"../src/weights/ner_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the NER model are quite good, accurately identifying animal names in sentences. If a sentence does not contain any animals, the model correctly returns no detected entities. When a sentence includes multiple animals, the model successfully recognizes and labels each of them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CAT'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.predict(\"This is my cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.predict(\"What will you say if do not want talk about that?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-CAT', 'B-ELEPHANT'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.predict(\"Can you imageine I was an elephant and a balck cat today!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
